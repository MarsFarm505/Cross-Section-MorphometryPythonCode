# VALLEY CROSS SECTION MORPHOMETRY 
# Paul D. Zimmer (zimmerpauld@gmail.com)
# 20 March 2024
#
# This Python script is an adaptation of MATLAB code created by Zimmer and Gabet (2018) and isolates
# the central valley within a given arbitrary cross section and calculates metrics for describing cross
# sectional shape below a user-specified height above the valley bottom. It creates a results table and
# figures depicting those metrics overlain on the cross section. 
# 
# As written, the code requires cross section elevation data generated by the ArcGIS Stack Profile Tool
# as a .dbf file, which includes three important fields: x values ('FIRST_DIST'), elevation values ('FIRST_Z'),
# and a unique identifier to establish which values are associated with a particular cross section ('LINE_ID').
# You can modify the input code to accept data in any format (.csv, .tab, etc.) and can include as many cross
# sections as you want in the table (this has worked with over 100k of them) so long as the data is formatted
# correctly. The following example table shows data for three "cross sections," which are numbered 1, 2, and 3:

# x	elev	ID
# 0	233	1
# 5	227	1
# 10	239	1
# 0	456	2
# 5	433	2
# 10	460	2
# 0	683	3	
# 5	666	3
# 10	691	3

# The user also has to specify the height above valley bottom to use for the calculations, which here is a
# percentage of the relief of the isolated valley (spec_pct). The code will create a new folder with the input
# table name, calculate the metrics, and output a results table and figures for each cross section showing the
# results of the V-index, quadratic curve fit, and power law curve fit. If using multiple input files, the code
# will export an additional table that combines all the output tables but adds a field with the input file name
# as an identifier. LINE_ID is changed to OBJ_ID in the output table to make it easier to join back to the cross
# sections in ArcGIS, since the Stack Profile tool uses the input cross section Object ID as the "LINE ID" for the
# tool's output .dbf

 

# install dependencies
import os
import pandas as pd
import numpy as np
import scipy as sp
from scipy import interpolate
from scipy.signal import find_peaks
from scipy.optimize import curve_fit
import matplotlib.pyplot as plt
from simpledbf import Dbf5
import time

# starts timer for code processing
starttime = time.time()

# creates empty list for creating output file 
output_all = []

# sets input directory
inpath = r'/Users/paulzimmer/Desktop/NewCS_dbfs/'

# sets percentage of valley height to use for calculation
spec_pct = 0.56 # specified height 56% of valley relief

# loops through input directory and finds all .dbf files
for filename in os.listdir(inpath):
    loopstart = time.time()
    
    # creates new folder for each input dbf, sets as new directory for output
    if filename.endswith('.dbf'):
        infile = str(inpath)+str(filename)
        outpath = str(inpath)+(os.path.splitext(filename)[0]+'_output')
        if not os.path.exists(outpath):
            os.mkdir(outpath)
        os.chdir(outpath)
        
        # imports dbf and converts to Pandas dataframe
        dbf = Dbf5(infile)
        basedf = dbf.to_dataframe()
        # creates copy of df with only relevant columns and renames
        newdf = basedf[['FIRST_DIST', 'FIRST_Z', 'LINE_ID']].copy()
        newdf.columns = ['x', 'y', 'LINE_ID']

        # splits the df by LINE_ID
        xs_list = [d for _, d in newdf.groupby(['LINE_ID'])]
        
        # initialize variables
        OBJ_ID = []
        V_Index = []
        Quad_c_Coeff = []
        Power_a_Coeff_Left = []
        Power_a_Coeff_Right = []
        Power_b_Coeff_Left = []
        Power_b_Coeff_Right = []
        Power_c_Coeff_Left = []
        Power_c_Coeff_Right = []
        Valmin_Elev = []
        V_Height = []
        
        # exception handling routine - outputs dummy variables to table and creates figure
        def NoCalc():
            OBJ_ID.append(xs['LINE_ID'].iloc[0])
            V_Index.append(99)
            Quad_c_Coeff.append(99)
            Power_b_Coeff_Left.append(99)
            Power_b_Coeff_Right.append(99)
            Valmin_Elev.append(y_center_elev)
            V_Height.append((max(xs['y'])-y_center_elev)*spec_pct)

            fig,ax1= plt.subplots(figsize=(8,5))
            plt.plot(xs['x'].values, xs['y'].values, color='black')

            plt.xlabel("Distance (m)")
            plt.ylabel("Elevation (m)")
            plt.title("No Calculation Performed")
            plt.gca().set_aspect(5)
            plt.savefig(str(xs['LINE_ID'].iloc[0])+"_NoCalc"+".png")
            plt.close()
        
        # loop through cross sections in each df and calculate metrics
        count = 0
        for xs in xs_list:
            print("Processing "+str(filename)+ " cross section " + str(xs.iloc[0,2]) +r" (xs_list["+ str(count) +"])",end='\r')
        
            # defines center of cross section
            y_center_elev = xs['y'].iloc[int(len(xs['x'])/2)]
            x_center = (max(xs['x'])-min(xs['x']))/2
           
            # splits cross section into left and right sides
            xs_left = xs[xs['x']<(max(xs['x'])/2)]
            xs_right = xs[xs['x']>(max(xs['x'])/2)]

            # clips cross section to elevation of lowest side 
            xs = xs.loc[xs['y'] <= (min(max(xs_left['y']),max(xs_right['y'])))]
                 
            # sets y values from df
            y_vals = (xs['y'])

            # indentifies local maxima
            peaks, _ = find_peaks(y_vals, height=None)
            pks_x = []
            pks_y = []
            for pk in peaks:
                xval = xs['x'].iloc[pk]
                elev = xs['y'].iloc[pk]
                pks_x.append(xval)
                pks_y.append(elev)
            
            # adds left and right ends of cross section as peaks
            pks_x.extend([xs['x'].iloc[0], xs['x'].iloc[-1]])
            pks_y.extend([xs['y'].iloc[0], xs['y'].iloc[-1]])

            # creates new dataframe with peak x and y values
            pks = pd.DataFrame({'x': pks_x, 'y': pks_y})

            # identifies the central valley between peaks closest to valley center
            try:
                # filters out peaks below specified elevation
                pks_sub = pks[pks['y']> ((max(xs['y'])-y_center_elev)*spec_pct)+y_center_elev]

                # identifies peak closest to valmin on left side of valley
                left_pk = max(pks_sub['x'][pks_sub['x']<x_center])
                # identifies peak closest to valmin on right side of valley
                right_pk = min(pks_sub['x'][pks_sub['x']>x_center])

                # clips cross section to lowest peak on either side of valley
                xs_clip = xs[(xs['x'] >= left_pk) & (xs['x'] <= right_pk)]
                xs = xs_clip
                ymin = min(xs['y'])
                xmin = xs.loc[xs['y'] == ymin, 'x'].iloc[0]
                ymax = max(xs['y'])
                min_relief = ymax-ymin

                # checks cross section ends are higher than middle (i.e., valley shaped)
                ycenter = xs['y'].iloc[int(len(xs['x'])/2)]
                if ycenter < min((xs['y'].iloc[-1], xs['y'].iloc[1])):
                    
                    # sets specified height above valley bottom
                    spec_ht = (ymax-ymin)*spec_pct
                    # sets elevation of specified height
                    v_elev = ymin + spec_ht

                    # extracts cross section below specified height
                    xtr = xs.loc[xs['y'] <= v_elev]

                    # creates a horizontal line with x vals from xtr and y val of v_elev
                    vht = xtr.assign(y = v_elev)
                    
                    # calculates area of triangle formed by vht and xmin
                    v_area = 0.5*(max(xtr['x']) - min(xtr['x']))* spec_ht #area of triangle

                    # calculates area between vht and portion of valley below using trapezoid calculation
                    xs_area = np.trapz(y=vht['y'] - xtr['y'], x=xtr['x'])
                    
                    # calculates V-index
                    v_index = (xs_area/v_area)-1

                    # plots V-index figure and saves to output folder
                    fig,ax1= plt.subplots(figsize=(8,5))
                    plt.plot(xs['x'].values, xs['y'].values, color='black')
                    plt.fill_between(xtr['x'].values.astype(float),vht['y'].values.astype(float), xtr['y'].values.astype(float), color='lightgrey')

                    trianglex = [min(vht['x']), max(vht['x']), xmin, min(vht['x'])]
                    triangley = [vht['y'].iloc[0], vht['y'].iloc[-1], ymin, vht['y'].iloc[0]]
                    plt.plot(trianglex,triangley,color='black', linestyle='--', dashes=(10,5), linewidth='0.5')
                    #plt.fill(trianglex,triangley,color='whitesmoke')

                    plt.xlabel("Distance (m)")
                    plt.ylabel("Elevation (m)")
                    plt.title("V-index = "+str("{:.2f}".format(v_index)))
                    plt.gca().set_aspect(5)
                    plt.savefig(str(xs['LINE_ID'].iloc[0])+"_V_Index"+".png")
                    plt.close()

                    # calculates quadratic curve fit
                    x_arr = np.array(xtr['x'])
                    y_arr = np.array(xtr['y'])
                    z = np.polyfit(x_arr, y_arr, 2)

                    def quadratic_func(x,a,b,c):    
                        return a + b*x + c*x**2

                    popt, pcov = curve_fit(quadratic_func, x_arr, y_arr)

                    # plots quadratic curve fit figure and saves to output folder
                    fig,ax1= plt.subplots(figsize=(8,5))
                    plt.plot(xs['x'].values, xs['y'].values, color='black')
                    plt.plot(xtr['x'].values, quadratic_func(xtr['x'].values, *popt), '--')
                    plt.xlabel("Distance (m)")
                    plt.ylabel("Elevation (m)")
                    plt.title("Quadratic fit exponent = "+ str('{:.3E}'.format(popt[2])))
                    plt.gca().set_aspect(5)
                    plt.savefig(str(xs['LINE_ID'].iloc[0])+"_Quad_Fit"+".png")
                    plt.close()

                    # calculates power law curve fits                    
                    # splits xs into left and right sides to calculate separately
                    xs_clip_left = xtr[xtr['x']< xtr['x'].mean()]
                    xs_clip_right = xtr[xtr['x']>xtr['x'].mean()]

                   
                    x_arr_left = np.array(xs_clip_left['x'])
                    x_arr_left = x_arr_left - min(x_arr_left)+1

                    y_arr_left = (np.array(xs_clip_left['y']))[::-1]
                    y_arr_left = y_arr_left - min(y_arr_left)+1

                    x_arr_right = np.array(xs_clip_right['x'])
                    x_arr_right = x_arr_right - min(x_arr_right)+1

                    y_arr_right = np.array(xs_clip_right['y'])
                    y_arr_right = y_arr_right - min(y_arr_right)+1

                    def power_law(x, a, b, c):
                        return a*x**b + c

                    # p0 values used to intialize variables and help solver
                    try:
                        popt_left, pcov_left = curve_fit(power_law, x_arr_left, y_arr_left, p0 = [(0.001, 2, 4)], maxfev=5000)
                    # if no solution, outputs dummy value of integer 1 to table
                    except RuntimeError:
                        popt_left = np.array([1,1,1])

                    try:
                        popt_right, pcov_right = curve_fit(power_law, x_arr_right, y_arr_right, p0 = [(0.001, 2, 4)], maxfev=5000)
                    except RuntimeError:
                        popt_right = np.array([1,1,1])

                    ## calculates r2 for power fits
                    # from sklearn.metrics import r2_score
                    # r_squared = r2_score(y_arr, power_law(x_arr, *popt), multioutput='variance_weighted')

                    # plots both power fits on one figure and saves to output folder
                    fig, ax = plt.subplots(ncols=2)
                    ax[0].plot(x_arr_left, y_arr_left, color='black')
                    ax[0].plot(x_arr_left, power_law(x_arr_left, *popt_left), '--', color='blue')
                    ax[0].invert_xaxis()
                    ax[0].set_title("Power b-coefficient = "+ str(round(popt_left[1],3)), fontsize=10)
                    ax[0].set_aspect(5)
                    ax[1].plot(x_arr_right, y_arr_right, color='black')
                    ax[1].plot(x_arr_right, power_law(x_arr_right, *popt_right), '--', color='blue')
                    ax[1].set_title("Power b-coefficient = "+ str(round(popt_right[1],3)), fontsize=10)
                    ax[1].set_aspect(5)
                    plt.savefig(str(xs['LINE_ID'].iloc[0])+"_Power_Fit"+".png")
                    plt.close()

                    # writes all calculated metrics for cross section to a list
                    OBJ_ID.append(xs['LINE_ID'].iloc[0])
                    V_Index.append(round(v_index,3))
                    Quad_c_Coeff.append(popt[2])
                    Power_b_Coeff_Left.append(popt_left[1])
                    Power_b_Coeff_Right.append(popt_right[1])
                    Valmin_Elev.append(ymin)
                    V_Height.append(spec_ht)

                # if cross section not "valley shaped"
                else:
                    NoCalc()
            # if error in valley isolation routine
            except:
                NoCalc()
                    
            count = count + 1

        # combines metrics into a single dataframe and saves to .csv in output folder
        baseDEM = [0]*count
        output = pd.DataFrame(list(zip(baseDEM, OBJ_ID, V_Index, Quad_c_Coeff, Power_b_Coeff_Left, Power_b_Coeff_Right, Valmin_Elev, V_Height)), columns=['Base_DEM','OBJ_ID','V_Index', 'Quad_a', 'Power_b_left', 'Power_b_right', 'Valmin_elev', 'V_Height'])
        output['Base_DEM']= os.path.splitext(filename)[0]
        output.to_csv(os.path.splitext(filename)[0]+'_metrics.csv', sep=',', index=False)
        output_all.append(output)
        loopend = time.time()
        print('\r')
        print("Processing completed in "+str(int(loopend-loopstart))+' seconds')

# exports single .csv with all cross sections to input folder        
os.chdir(inpath)        
combined = pd.concat(output_all)
combined.to_csv('All_metrics.csv', sep=',', index=False)
endtime = time.time()
print('All processing completed in '+ str(int(endtime-starttime))+' seconds')

